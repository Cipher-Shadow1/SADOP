# SADOP Endpoint Routing - How It Works

## ğŸ“ Current Architecture

### Frontend â†’ Backend Flow

```
User Input (Frontend)
    â†“
/assistant endpoint (SINGLE ENTRY POINT)
    â†“
classify_prompt() [llm_router.py]
    â†“
Routes to appropriate handler
```

---

## ğŸ§  Intelligent Classification

**File:** `BackEnd/llm_router.py` â†’ `classify_prompt()`

**How it detects:**

```python
classification_prompt = """
User Input: "{user_input}"

Classification Rules:
1. If contains SQL (SELECT, INSERT, etc.) â†’ "sql_query"
2. If asks "best query for...", "optimized query for..." â†’ "query_generation"
3. If asks "why slow?", "performance issues?" â†’ "general_question"
4. If asks for index recommendations â†’ "optimization_request"
```

**Uses:** Groq LLM (Llama 3.3 70B) to classify!

---

## ğŸ”€ Routing Logic

**File:** `BackEnd/main.py` â†’ `/assistant` endpoint

### Current Routing:

```python
classification = classify_prompt(user_input)

if classification["type"] == "sql_query":
    # Run full ML + RL + LLM diagnosis
    return {...diagnosis...}

elif classification["type"] == "general_question":
    # Return general advice with tool awareness
    return handle_general_question(user_input)

elif classification["type"] == "optimization_request":
    # Return optimization tips
    return handle_optimization_request(user_input)

# MISSING: query_generation handler!
```

---

## âŒ Current Gap

**Query generation requests NOT handled by `/assistant`!**

User says: _"best query for user from Algeria"_

- âœ… Classifies as `query_generation`
- âŒ But `/assistant` doesn't route it!
- Falls through to `general_question` handler

---

## âœ… Solution

Add query generation routing to `/assistant` endpoint!

---

## ğŸ“Š Frontend Code

**File:** `frontend/app/page.tsx`

```tsx
// Frontend ALWAYS uses /assistant
const res = await fetch(`${apiUrl}/assistant`, {
  method: "POST",
  body: JSON.stringify({ message: input }),
});

// Backend handles routing automatically!
// No frontend logic needed!
```

---

## ğŸ¯ Complete Flow Example

### Example 1: SQL Query

```
User: "SELECT * FROM user"
  â†“
Frontend â†’ /assistant
  â†“
classify_prompt() â†’ "sql_query"
  â†“
Runs ML + RL + LLM
  â†“
Returns diagnosis
```

### Example 2: Query Generation

```
User: "best query for user from Algeria"
  â†“
Frontend â†’ /assistant
  â†“
classify_prompt() â†’ "query_generation"
  â†“
(CURRENTLY MISSING!)
Should call generate_optimized_query logic
  â†“
Returns best query + diagnosis
```

### Example 3: General Question

```
User: "Why is my system slow?"
  â†“
Frontend â†’ /assistant
  â†“
classify_prompt() â†’ "general_question"
  â†“
handle_general_question()
  â†“
Returns tool-aware response
```

---

## ğŸ”§ Fix Needed

Add to `/assistant` endpoint in `main.py`:

```python
elif classification["type"] == "query_generation":
    # Generate 3 variations, diagnose, select best
    variations = generate_query_variations(user_input)
    # ... scoring logic ...
    return best_query_result
```

**Status:** NOT implemented yet - explaining to user now!
